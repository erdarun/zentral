#!/usr/bin/python
from datetime import timedelta
from decimal import Decimal
import hashlib
import json
import os
import plistlib
import ssl
import subprocess
import sys
import urllib2
import warnings
import zlib

MANAGED_INSTALLS_DIR = "/Library/Managed Installs"
ARCHIVES_DIR = os.path.join(MANAGED_INSTALLS_DIR, "Archives")

SAL_BUNDLE_ID = "com.salsoftware.sal"
# Currently not used
SAL_KEY_PREFERENCE = "enrolment_key"
SAL_SERVER_PREFERENCE = "ServerURL"

USER_AGENT = "Zentral/mnkpf 0.2"
ZENTRAL_API_ENDPOINT = "https://%TLS_HOSTNAME%/munki/"
ZENTRAL_API_SERVER_CERTIFICATE = "%TLS_SERVER_CERTS%"
ZENTRAL_API_SECRET_HEADER = "Zentral-API-Secret"
ZENTRAL_API_SECRET = "%API_SECRET%"

SANTACTL = "/usr/local/bin/santactl"
SYSTEM_PROFILER = "/usr/sbin/system_profiler"

# SAL infos


def get_sal_infos():
    """Returns dict of preferences set for Sal, minimum should be key (for business unit)
    and ServerURL (unless inherited from DNS/Sal default of 'http://sal/"""
    # ../sal-scripts/blob/3e11bb5ffe654869a6d6aeebb65418b0d13e9eeb/utils.py#L39
    try:
        from Foundation import (CFPreferencesCopyKeyList,
                                kCFPreferencesAnyUser,
                                kCFPreferencesCurrentHost,
                                CFPreferencesCopyAppValue)
        infos = {}
        for key in CFPreferencesCopyKeyList(SAL_BUNDLE_ID,
                                            kCFPreferencesAnyUser,
                                            kCFPreferencesCurrentHost) or []:
            val = CFPreferencesCopyAppValue(key, SAL_BUNDLE_ID)
            if val is not None:
                infos[key] = val
        return infos
    except ImportError:
        print "Could not import CFPreferencesCopyAppValue. Not on OSX ?"

# OSX apps


def get_santa_versions():
    """Returns component versions of santa, including kext, daemon, job control script,
    and GUI (santa-driver, santad, santactl, and SantaGUI, respectively)"""
    versions = {}
    try:
        stdout = subprocess.check_output([SANTACTL, "version"])
    except (OSError, subprocess.CalledProcessError):
        pass
    else:
        # if previous check_output command in the try was successful,
        for line in stdout.splitlines():
            component, version = (s.strip() for s in line.split('|'))
            versions[component] = version
    return versions


def cleanup_santa_fileinfo_dict(d):
    for k in d:
        v = d.pop(k)
        k = k.lower().replace(' ', '_').replace('-', '_')
        if v == "Yes":
            v = True
        elif v == "No":
            v = False
        elif v == "None":
            v = None
        elif isinstance(v, list):
            v = [cleanup_santa_fileinfo_dict(vd) for vd in v]
        d[k] = v
    return d


def get_santa_fileinfo(bundle_path):
    """ Get's app bundle paths from munki's AppInventory, returns dict of parsed
    output from santactl, including Path, SHA-256/1, Bundle Name/Version/
    BundleVersionString values, type (executable), if code-signed, santas rules
    for handling, cert/signing chain info"""
    try:
        stdout = subprocess.check_output([SANTACTL, "fileinfo", "--json", bundle_path])
    except subprocess.CalledProcessError:
        return {}
    stdout = stdout.strip()
    try:
        fileinfo = json.loads(stdout)[0]
    except:
        # workaround for older santa versions
        try:
            stdout = stdout[stdout.index('{'):]
        except ValueError:
            return {}
        fileinfo = json.loads(stdout)
    fileinfo = cleanup_santa_fileinfo_dict(fileinfo)
    return fileinfo


class ApplicationInventory(object):
    APPLICATION_INVENTORY = os.path.join(MANAGED_INSTALLS_DIR, "ApplicationInventory.plist")

    def __init__(self):
        try:
            self.data = plistlib.readPlist(self.APPLICATION_INVENTORY)
        except IOError:
            print "Could not read application inventory plist"
            self.data = []

    def get_osx_app_instances(self, include_santa_fileinfo=False):
        apps = []
        if include_santa_fileinfo and not get_santa_versions():
            # asked a full report but santa is not installed
            include_santa_fileinfo = False
        for app_d in self.data:
            osx_app_instance = {'app': {'bundle_id': app_d['bundleid'],
                                        'bundle_name': app_d['CFBundleName'],
                                        'bundle_version_str': app_d['version']},
                                'bundle_path': app_d['path'],
                                }
            if include_santa_fileinfo:
                fileinfo = get_santa_fileinfo(osx_app_instance['bundle_path'])
                if not fileinfo:
                    warnings.warn('Bundle {} without santa fileinfo'.format(osx_app_instance['app']['bundle_id']))
                else:
                    signing_chain = fileinfo.get('signing_chain', None)
                    if not signing_chain:
                        signed_by = None
                    else:
                        signed_by = signing_chain.pop(0)
                        current_signed_by = signed_by
                        while signing_chain:
                            current_signed_by_signed_by = signing_chain.pop(0)
                            current_signed_by['signed_by'] = current_signed_by_signed_by
                            current_signed_by = current_signed_by_signed_by
                    if 'bundle_version' in fileinfo:
                        osx_app_instance['app'].update({'bundle_version': fileinfo['bundle_version']})
                    osx_app_instance.update({'path': fileinfo.get('path', None),
                                             'sha_1': fileinfo['sha_1'],
                                             'sha_256': fileinfo['sha_256'],
                                             'type': fileinfo['type'],
                                             'signed_by': signed_by})
            apps.append(osx_app_instance)
        return include_santa_fileinfo, apps

# Munki run reports


class ManagedInstallReport(object):
    def __init__(self, filename):
        self.basename = os.path.basename(filename)
        self.sha1sum = self._get_sha1_sum(filename)
        self.data = plistlib.readPlist(filename)
        self.start_time = self.data['StartTime']
        self.end_time = self.data.get('EndTime', self.start_time)
        try:
            self.munki_version = self.data['MachineInfo']['munki_version']
        except KeyError:
            self.munki_version = None

    @staticmethod
    def _get_sha1_sum(filename):
        sha1 = hashlib.sha1()
        with open(filename, 'rb') as f:
            # TODO: chunking if the file is big
            sha1.update(f.read())
        return sha1.hexdigest()

    def _events(self):
        events = [(self.start_time, {'type': 'start'})]
        for ir in self.data['InstallResults']:
            events.append((ir.pop('time').strftime('%Y-%m-%d %H:%M:%S +0000'),
                           dict(ir, type='install')))
        for rr in self.data['RemovalResults']:
            events.append((rr.pop('time').strftime('%Y-%m-%d %H:%M:%S +0000'),
                           dict(rr, type='removal')))
        for err in self.data['Errors']:
            events.append((self.end_time, {'type': 'error', 'message': err}))
        for warn in self.data['Warnings']:
            events.append((self.end_time, {'type': 'warning', 'message': warn}))
        events.sort()
        return events

    def serialize(self):
        d = {'basename': self.basename,
             'sha1sum': self.sha1sum,
             'run_type': self.data['RunType'],
             'start_time': self.start_time,
             'end_time': self.end_time,
             'events': self._events()}
        if self.munki_version:
            d['munki_version'] = self.munki_version
        return d


def iter_manage_install_reports():
    last_report = os.path.join(MANAGED_INSTALLS_DIR, 'ManagedInstallReport.plist')
    if os.path.exists(last_report):
        yield last_report
    if os.path.isdir(ARCHIVES_DIR):
        for filename in sorted(os.listdir(ARCHIVES_DIR), reverse=True):
            yield os.path.join(ARCHIVES_DIR, filename)


def build_reports_payload(last_seen=None):
    """ Unpacks ManagedInstallReport generator object, initializes MIR objects,
    skips if already processed, otherwise serializes & returns payload"""
    payload = []
    for filepath in iter_manage_install_reports():
        mir = ManagedInstallReport(filepath)
        if last_seen is not None and mir.sha1sum == last_seen:
            break
        payload.append(mir.serialize())
    return payload

# Machine infos


class SystemProfilerReport(object):
    def __init__(self):
        p = subprocess.Popen([SYSTEM_PROFILER, '-xml',
                              'SPHardwareDataType',
                              'SPSoftwareDataType',
                              'SPStorageDataType'],
                             stdout=subprocess.PIPE)
        stdoutdata, _ = p.communicate()
        self.data = plistlib.readPlistFromString(stdoutdata)

    def _get_data_type(self, data_type):
        for subdata in self.data:
            if subdata['_dataType'] == data_type:
                return subdata

    def get_machine_snapshot(self):
        """ Parses sysprofiler output, returns a dict w/three sub-dicts for
        serial / model, CPU, RAM / OS major-minor-patch"""
        # Hardware
        data = self._get_data_type('SPHardwareDataType')
        if len(data['_items']) != 1:
            raise ValueError('0 or more than one item in a SPHardwareDataType output!')
        item_d = data['_items'][0]

        serial_number = item_d['serial_number']
        system_info = {'hardware_model': item_d['machine_model'],
                       'cpu_type': item_d.get('cpu_type', None)}
        # RAM
        ram_multiplicator = None
        ram_amount, ram_amount_unit = item_d['physical_memory'].split()
        if ram_amount_unit == 'GB':
            ram_multiplicator = 2**30
        elif ram_amount_unit == 'MB':
            ram_multiplicator = 2**20
        else:
            warnings.warn('Unknown ram amount unit {}'.format(ram_amount_unit))
        if ram_multiplicator:
            system_info['physical_memory'] = int(Decimal(ram_amount.replace(",", ".")) * ram_multiplicator)

        # Software
        data = self._get_data_type('SPSoftwareDataType')
        if len(data['_items']) != 1:
            raise ValueError('0 or more than one item in a SPSoftwareDataType output!')
        item_d = data['_items'][0]

        system_info['computer_name'] = item_d['local_host_name']

        # uptime
        # up 7:21:19:44
        uptime = item_d['uptime'].rsplit(" ", 1)[-1]
        td_kwargs = dict(zip(("seconds", "minutes", "hours", "days"),
                             (int(n) for n in uptime.split(":")[::-1])))
        uptime = int(timedelta(**td_kwargs).total_seconds())

        # OS version
        os_version = item_d['os_version']
        os_name, os_version_str, os_build = os_version.rsplit(' ', 2)
        os_build = os_build.strip('()')
        os_version = {'name': os_name,
                      'build': os_build}
        os_version.update(dict(zip(['major', 'minor', 'patch'],
                                   (int(s) for s in os_version_str.split('.')))))
        return {'serial_number': serial_number,
                'system_info': system_info,
                'os_version': os_version,
                'system_uptime': uptime}

# Zentral Munki API calls


def make_api_request(url, data=None):
    req = urllib2.Request(url)
    req.add_header('User-Agent', USER_AGENT)
    req.add_header(ZENTRAL_API_SECRET_HEADER, ZENTRAL_API_SECRET)
    if data:
        data = json.dumps(data)
        req.add_header('Content-Type', 'application/json')
        data = zlib.compress(data, 9)
        req.add_header('Content-Encoding', 'deflate')
    if ZENTRAL_API_SERVER_CERTIFICATE:
        ctx = ssl.create_default_context(cafile=ZENTRAL_API_SERVER_CERTIFICATE)
    else:
        ctx = ssl.create_default_context()
    response = urllib2.urlopen(req, data=data, context=ctx)
    return json.load(response)


def get_job_details(machine_serial_number):
    url = "{}/job_details/".format(ZENTRAL_API_ENDPOINT.strip('/'))
    return make_api_request(url, {'machine_serial_number': machine_serial_number})


def post_job(data):
    url = "{}/post_job/".format(ZENTRAL_API_ENDPOINT.strip('/'))
    return make_api_request(url, data)


# Main


if __name__ == '__main__':
    run_type = None
    try:
        run_type = sys.argv[1]
    except IndexError:
        pass
    spr = SystemProfilerReport()
    # initialize data dict
    data = {'machine_snapshot': spr.get_machine_snapshot()}
    sal_infos = get_sal_infos()
    if sal_infos is not None:
        data['sal_infos'] = sal_infos
    msn = data['machine_snapshot']['serial_number']
    job_details = get_job_details(msn)
    ai = ApplicationInventory()
    # if it's both an auto run (vs. debug/testing) and we have santa fileinfo collected
    data['include_santa_fileinfo'] = run_type == 'auto' and job_details['include_santa_fileinfo']
    # retain the boolean about whether we've included santa fileinfo, populate w/ info or []
    (data['santa_fileinfo_included'],
     data['machine_snapshot']['osx_app_instances']) = ai.get_osx_app_instances(data['include_santa_fileinfo'])
    last_seen_sha1sum = job_details.get('last_seen_sha1sum', None)
    data['reports'] = build_reports_payload(last_seen_sha1sum)
    post_job(data)
    print ('Zentral postflight job OK - '
           'run type %s, fileinfo %s, last sha1sum %s') % (run_type or "-",
                                                           data['include_santa_fileinfo'],
                                                           (last_seen_sha1sum or "-")[:7])
